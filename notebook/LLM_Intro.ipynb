{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAflu5rRGjYo+3nIF88roY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/am88tech/gen-ai-ml/blob/main/notebook/LLM_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gCx0d6pe8qYy"
      },
      "outputs": [],
      "source": [
        "!pip install OpenAI\n",
        "!pip install langchain\n",
        "!pip install Cohere\n",
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basics of Gen AI"
      ],
      "metadata": {
        "id": "JmBiuWxMwqWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('COHERE')"
      ],
      "metadata": {
        "id": "J0IQXZsD-g50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"COHERE\"] = userdata.get('COHERE');"
      ],
      "metadata": {
        "id": "e2c_rUyD-o78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Cohere"
      ],
      "metadata": {
        "id": "kj4rQIOx_DsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=Cohere()\n",
        "result=llm.invoke(\"Provide me the stats of IPL 2025\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "6-d3gm_W_OTH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.llms import Cohere\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get the API key from userdata\n",
        "cohere_api_key = userdata.get('COHERE')\n",
        "\n",
        "# Set the COHERE_API_KEY environment variable\n",
        "os.environ[\"COHERE_API_KEY\"] = cohere_api_key\n",
        "\n",
        "# Now initialize the Cohere LLM\n",
        "llm = Cohere()\n",
        "result = llm.invoke(\"Provide me the stats of IPL 2025\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "YDF4lVfA-7M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a list of log messages\n",
        "log_messages = [\n",
        "    \"INFO: Server started successfully\",\n",
        "    \"WARNING: Low disk space\",\n",
        "    \"CRITICAL: Database connection failed\",\n",
        "    \"CRITICAL: Security breach detected\",\n",
        "    \"INFO: New feature released\",\n",
        "]\n",
        "\n",
        "# Create a DataFrame with 10 rows and 1 column\n",
        "df = pd.DataFrame(log_messages, columns=[\"Message\"])\n",
        "# Classify each log message using llm.invoke\n",
        "df[\"Sentiment\"] = df[\"Message\"].apply(lambda message: llm.invoke(f\"Classify the severity of this log message make give output as CRITICAL if the message is critical: {message}\"))\n",
        "df"
      ],
      "metadata": {
        "id": "xzxY38P_AFv_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}